# ğŸš„ Geospatial Train Tracking & Delay Analysis
![Project Visual](folium_popup_map.png)

**Credit:** This project was only possible thanks to Realtime Trains API!

## ğŸ“Œ Project Overview
This project analyzes train delays at **Finsbury Park (FPK)**, capturing **all arriving trains**, regardless of their origin. The project uses **FastAPI, PostgreSQL, SQLAlchemy, Pandas, and AsyncSession** for efficient database operations. Additionally, it includes **geospatial mapping with Folium & GeoPandas**.

## ğŸ“‚ Project Structure
```
/train-tracking
â”‚â”€â”€ main.py                # ğŸ”„ Runs the full data pipeline & API
â”‚â”€â”€ config.py              # ğŸ› ï¸ Stores API credentials & configurations
â”‚â”€â”€ integrate_data.py # ğŸ”„ Merges train arrival and station geospatial data 
|
â”œâ”€â”€ data_pipeline/         # ğŸŒ Data processing scripts
â”‚   â”‚â”€â”€ extract.py         # ğŸ“€ Extracts arrivals from RTT API (past 7 days)
â”‚   â”‚â”€â”€ clean.py           # ğŸŒ± Cleans & processes data (calculates delays, adjust dates)
â”‚   â”‚â”€â”€ utils.py           # ğŸ¢ Uploads processed data to PostgreSQL
â”‚
â”œâ”€â”€ db/                    # ğŸ“ Database setup & schema
â”‚   â”‚â”€â”€ db_main.py         # ğŸ”§ Manages database connection
â”‚   â”‚â”€â”€ db_schema.py       # ğŸ“š Defines SQLAlchemy models (includes origin/destination CRS)
â”‚   â”‚â”€â”€ db_init.py         # ğŸ› ï¸ Initialises PostgreSQL tables
â”‚
â”œâ”€â”€ geospatial/ # ğŸ› ï¸ Geospatial mapping code
â”‚   |â”€â”€get_spatial_data.py 
â”‚   |â”€â”€ mapping.py # Creates interactive maps using merged data 
|
â”œâ”€â”€ data/ # ğŸ› ï¸ Extracted geospatial data from doogal.co.uk 
â”‚   â”‚â”€â”€ station_data.json # Raw station data in JSON format 
â”‚   â”‚â”€â”€ station_coordinates.csv # Processed station coordinates 
â”‚
â”œâ”€â”€ geodata/ # ğŸ› ï¸ Generated train maps 
â”‚   â”‚â”€â”€ train_delays_maps.html # Interactive map with delay info
|
â”œâ”€â”€ services/              # ğŸ› ï¸ API interaction scripts
â”‚   â”‚â”€â”€ trains_main.py     # ğŸšƒ Fetches arrival data & structures JSON
â”‚
â”œâ”€â”€ sql/                   # ğŸ“ˆ SQL Optimization Scripts
â”‚   â”‚â”€â”€ 01_create_partition.sql  # ğŸ“Š Partitioning tables by date
â”‚   â”‚â”€â”€ 02_create_indexes.sql    # âš–ï¸ Indexing to speed up queries
â”‚   â”‚â”€â”€ 03_slow_vs_fast_queries.sql  # ğŸ”¢ Performance benchmarking
â”‚   â”‚â”€â”€ 04_results.md   # ğŸ“˜ Performance improvement docs
â”‚
â”œâ”€â”€ outputs/               # ğŸ“… Data storage
â”‚   â”‚â”€â”€ raw_data_FPK_YYYY-MM-DD.json  # ğŸ“ Unfiltered API responses
â”‚   â”‚â”€â”€ cleaned_data.csv   # ğŸ“ˆ Processed train data
â”‚   â”‚â”€â”€ missing_actual_arrivals.csv   # âš ï¸ Trains with missing actual arrival times
|
â”œâ”€â”€ docs/               # ğŸ“– Detailed documentation 
â”‚   â”‚â”€â”€ 00_project_setup.md 
â”‚   â”‚â”€â”€ 01_db_setup 
â”‚   â”‚â”€â”€ 02_geo_setup.md
|   |â”€â”€ 03_merge_datasets.md
â”‚
â”œâ”€â”€ environment.yml        # ğŸ› ï¸ Conda environment setup
â”‚
â””â”€â”€ README.md              # ğŸ“— Project documentation
```

## âš™ï¸ Setting Up the Environment
- Install **Miniconda**, create an isolated environment:
  ```bash
  conda create --name trains_env python=3.9
  conda env create -f environment.yml
  conda activate trains_env
  ```
- Add RTT API credentials to `.env`:
  ```bash
  RTT_USERNAME=<your_guess>
  RTT_PASSWORD=(another_guess>)
  RTT_ENDPOINT=<your_endpoint>
  ```
- Initialise the database:
  ```bash
  python db/db_init.py
  ```

## ğŸš€ Running the Train API & Data Pipeline
When the FastAPI server starts, it automatically **fetches and processes train arrival data for the past 7 days** (including adjusting dates for next-day arrivals) and uploads it to the database. If the database is empty, the server must be running to extract the initial data.

```bash
uvicorn main:app --reload
```

### ğŸ¢ API Endpoints
| Endpoint | Description |
|--|--|
| `/api/station/FPK/date/2025-02-01` | Get arrivals at FPK for a specific date |
| `/` | Check if API is running |

## ğŸ“š PostgreSQL Database Setup - revised on 4 February 
### ğŸ”„ Data Model
| Column | Type | Description |
|--|--|--|
| `run_date` | DATE | Adjusted date of train arrival |
| `non_adjusted_date` | DATE | Original date as provided by the RTT API |
| `service_id` | STRING | Unique train ID |
| `operator` | STRING | Train company |
| `origin` | STRING | Departure station |
| `origin_csr` | STRING | Departure station code |
| `destination` | STRING | Arrival station |
| `destination_csr` | STRING | Arrival station code |
| `scheduled_arrival` | TIMESTAMP | Scheduled arrival time |
| `actual_arrival` | TIMESTAMP | Actual arrival time (if available) |
| `is_actual` | BOOLEAN | True if real arrival recorded |
| `delay_minutes` | INTEGER | Delay in minutes |
| `is_passenger_train` | BOOLEAN |	True if the train is a passenger service |
|  `next_day_arrival`	| BOOLEAN |	True if the arrival occurs after midnight |
| `was_scheduled_to_stop` |	BOOLEAN	| True if the stop was originally scheduled |
| `stop_status`	| STRING |	Display status (e.g., "CALL") |

### ğŸ“ˆ Query Optimisation
- **Partitioning**: Splits tables by `run_date`
- **Indexing**: Speeds up searches on `run_date`, `destination`
- **Result**: Queries run **120x faster**!

### **Geospatial Mapping**
Inputs:
- Train Arrival Data: `outputs/cleaned_data.csv` (includes station names) 
- Station Geospatial Data: `data/stations_coordinates.csv` (contains both station names and their codes as well as their latitutude and longitude) 
Steps:

1. Verify data structure 
2. Merge the Datasets with separate script `integrate_data.py`
3. Updated the schema and reinitiliase the database 
4. Update Mapping to use the merged dataset fro visualising train delays and station locations  

In Progress:  Visualising delay hotspots 

## ğŸ“º Next Steps
- **Performance Dashboards**: Operator performance analysis
- **CI/CD Pipelines**: Automate deployment with Docker & GitHub Actions

## ğŸ“¢ Disclaimer
Realtime Trains API data is for **non-commercial use only** and requires attribution.


---

### Notes on the Updates:
Update 4 February 2025
- Added folders for merged datasets.
- Updated databse scheme to include `origin_crs` and `destination_crs`.
- Corrected delay calculation logic in the ETL process to handle next-day arrivals properly. 

Update 3 February 2025
- Revised project structureto include updated names and descriptions.
- Enhanced ETL process to automatically adjust dates for next-day arrivals. 


The "Running the Train API & Data Pipeline" section notes that the project automatically processes data (including date adjustments for next-day arrivals).
