# ğŸš„ Geospatial Train Tracking & Delay Analysis

**Credit:** This project was only possible thanks to Realtime Trains API!

## ğŸ“Œ Project Overview
This project analyzes train delays at **Finsbury Park (FPK)**, capturing **all arriving trains**, regardless of their origin. The project uses **FastAPI, PostgreSQL, SQLAlchemy, Pandas, and AsyncSession** for efficient database operations. Future updates will include **geospatial mapping with Folium & GeoPandas**.

## ğŸ“‚ Project Structure
```
/train-tracking
â”‚â”€â”€ main.py                # ğŸ”„ Runs the full data pipeline & API
â”‚â”€â”€ config.py              # ğŸ› ï¸ Stores API credentials & configurations
â”‚
â”œâ”€â”€ data_pipeline/         # ğŸŒ Data processing scripts
â”‚   â”‚â”€â”€ extract.py         # ğŸ“€ Extracts arrivals from RTT API (past 7 days)
â”‚   â”‚â”€â”€ clean.py           # ğŸŒ± Cleans & processes data (calculates delays, adjust dates)
â”‚   â”‚â”€â”€ utils.py           # ğŸ¢ Uploads processed data to PostgreSQL
â”‚
â”œâ”€â”€ db/                    # ğŸ“ Database setup & schema
â”‚   â”‚â”€â”€ db_main.py         # ğŸ”§ Manages database connection
â”‚   â”‚â”€â”€ db_schema.py       # ğŸ“š Defines SQLAlchemy models
â”‚   â”‚â”€â”€ db_init.py         # ğŸ› ï¸ Initialises PostgreSQL tables
â”‚
â”œâ”€â”€ services/              # ğŸ› ï¸ API interaction scripts
â”‚   â”‚â”€â”€ trains_main.py     # ğŸšƒ Fetches arrival data & structures JSON
â”‚
â”œâ”€â”€ sql/                   # ğŸ“ˆ SQL Optimization Scripts
â”‚   â”‚â”€â”€ 01_create_partition.sql  # ğŸ“Š Partitioning tables by date
â”‚   â”‚â”€â”€ 02_create_indexes.sql    # âš–ï¸ Indexing to speed up queries
â”‚   â”‚â”€â”€ 03_slow_vs_fast_queries.sql  # ğŸ”¢ Performance benchmarking
â”‚   â”‚â”€â”€ 04_results.md   # ğŸ“˜ Performance improvement docs
â”‚
â”œâ”€â”€ outputs/               # ğŸ“… Data storage
â”‚   â”‚â”€â”€ raw_data_FPK_YYYY-MM-DD.json  # ğŸ“ Unfiltered API responses
â”‚   â”‚â”€â”€ cleaned_data.csv   # ğŸ“ˆ Processed train data
â”‚   â”‚â”€â”€ missing_actual_arrivals.csv   # âš ï¸ Trains with missing actual arrival times
â”‚
â”œâ”€â”€ environment.yml        # ğŸ› ï¸ Conda environment setup
â”‚
â””â”€â”€ README.md              # ğŸ“— Project documentation
```

## âš™ï¸ Setting Up the Environment
- Install **Miniconda**, create an isolated environment:
  ```bash
  conda create --name trains_env python=3.9
  conda env create -f environment.yml
  conda activate trains_env
  ```
- Add RTT API credentials to `.env`:
  ```bash
  RTT_USERNAME=<your_guess>
  RTT_PASSWORD=(another_guess>)
  RTT_ENDPOINT=<your_endpoint>
  ```
- Initialise the database:
  ```bash
  python db/db_init.py
  ```

## ğŸš€ Running the Train API & Data Pipeline
When the FastAPI server starts, it automatically **fetches and processes train arrival data for the past 7 days** (including adjusting dates for next-day arrivals) and uploads it to the database. If the database is empty, the server must be running to extract the initial data.

```bash
uvicorn main:app --reload
```

### ğŸ¢ API Endpoints
| Endpoint | Description |
|--|--|
| `/api/station/FPK/date/2025-02-01` | Get arrivals at FPK for a specific date |
| `/` | Check if API is running |

## ğŸ“š PostgreSQL Database Setup
### ğŸ”„ Data Model
| Column | Type | Description |
|--|--|--|
| `run_date` | DATE | Adjusted date of train arrival |
| `non_adjusted_date` | DATE | Original date as provided by the RTT API |
| `service_id` | STRING | Unique train ID |
| `operator` | STRING | Train company |
| `origin` | STRING | Departure station |
| `destination` | STRING | Arrival station |
| `scheduled_arrival` | TIMESTAMP | Scheduled arrival time |
| `actual_arrival` | TIMESTAMP | Actual arrival time (if available) |
| `is_actual` | BOOLEAN | True if real arrival recorded |
| `delay_minutes` | INTEGER | Delay in minutes |
| `is_passenger_train` | BOOLEAN |	True if the train is a passenger service |
|  `next_day_arrival`	| BOOLEAN |	True if the arrival occurs after midnight |
| `was_scheduled_to_stop` |	BOOLEAN	| True if the stop was originally scheduled |
| `stop_status`	| STRING |	Display status (e.g., "CALL") |

### ğŸ“ˆ Query Optimisation
- **Partitioning**: Splits tables by `run_date`
- **Indexing**: Speeds up searches on `run_date`, `destination`
- **Result**: Queries run **120x faster**!

## ğŸ“º Next Steps
- **Geospatial Mapping**: Visualising delay hotspots with Folium & GeoPandas
- **Performance Dashboards**: Operator performance analysis
- **CI/CD Pipelines**: Automate deployment with Docker & GitHub Actions

## ğŸ“¢ Disclaimer
Realtime Trains API data is for **non-commercial use only** and requires attribution.


---

### Notes on the Updates:
- **Project Structure:**  
  The structure now includes updated names and descriptions reflecting the new database fields and the adjusted ETL process.
  
- **Database Schema:**  
  The Data Model section now includes `non_adjusted_date` (storing the original API date) alongside `run_date` (the adjusted date).

- **ETL Process:**  
  The "Running the Train API & Data Pipeline" section notes that the project automatically processes data (including date adjustments for next-day arrivals).
